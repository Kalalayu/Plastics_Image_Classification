# -*- coding: utf-8 -*-
"""Plastics_Image_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k2lZzlR1ucFMlG2HH9JAeP-bntpVNUVP
"""

from google.colab import files
import zipfile
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

uploaded = files.upload()

zip_path = '/content/Dataset_plastics_mhadlekar_UN-20250720T182641Z-1-001.zip'
base_dir='/content/Dataset_plastics_mhadlekar_UN/Dataset_plastics_mhadlekar_UN'            # destination

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall('/content/Dataset_plastics_mhadlekar_UN') # Extract to the outer directory

# Data Preprocessing with the given parameters
# Define target image size
IMG_HEIGHT = 256
IMG_WIDTH = 256

# Define augmentation parameters and validation split
image_gen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=45,
    width_shift_range=.15,
    height_shift_range=.15,
    horizontal_flip=True,
    zoom_range=0.5,
    validation_split=0.25  # 25% for validation (1/4)
)

# Set up data generators for training and validation
train_data_gen = image_gen.flow_from_directory(
    directory=base_dir,
    batch_size=32,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='categorical', # Use 'categorical' for multi-class classification
    subset='training', # training subset
    seed=123 # seed for reproducibility
)

val_data_gen = image_gen.flow_from_directory(
    directory=base_dir,
    batch_size=32,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='categorical', # Use 'categorical' for multi-class classification
    subset='validation', # validation subset
    seed=123 # seed for reproducibility
)

# print the number of images found in each set to verify the split
print(f"Number of training images: {train_data_gen.samples}")
print(f"Number of validation images: {val_data_gen.samples}")

# Print class indices for mapping class names to numerical labels
print("\nClass indices:")
print(train_data_gen.class_indices)

# Model Building

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(train_data_gen.num_classes, activation='softmax') # Output layer with number of classes and softmax
])

model.summary()

# Model Compilation
model.compile(optimizer='adam',
              loss='categorical_crossentropy', # Use categorical_crossentropy for multi-class
              metrics=['accuracy', tf.keras.metrics.Precision()])

# Model Training
epochs = 30
history = model.fit(
    train_data_gen,
    steps_per_epoch=train_data_gen.samples // train_data_gen.batch_size,
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=val_data_gen.samples // val_data_gen.batch_size
)

# Evaluate the model on the validation set
loss, accuracy, precision = model.evaluate(val_data_gen)
print(f"Validation Loss: {loss:.4f}")
print(f"Validation Accuracy: {accuracy:.4f}")
print(f"Validation Precision: {precision:.4f}")

# i) Plot training accuracy and precision graph
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
precision_train = history.history['precision_1']
val_precision = history.history['val_precision_1']
epochs_range = range(epochs)

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(epochs_range, precision_train, label='Training Precision')
plt.plot(epochs_range, val_precision, label='Validation Precision')
plt.legend(loc='lower right')
plt.title('Training and Validation Precision')
plt.xlabel('Epoch')
plt.ylabel('Precision')
plt.grid(True)

plt.tight_layout()
plt.show()

# ii) Plot confusion matrix
# Get the true labels and predicted labels for the validation set
val_data_gen.reset() # Reset generator to ensure predictions match true labels
y_true = val_data_gen.classes[val_data_gen.index_array]

# Predict the classes for the validation set
y_pred_proba = model.predict(val_data_gen)
y_pred = np.argmax(y_pred_proba, axis=1)

# Get the class names
class_names = list(val_data_gen.class_indices.keys())

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Print classification report
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))



"""Image classification to identify different types of plastics: HDPE, LDPA, PET, and PP."""